{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Galvanic Skin Response GSR\n",
    "gsr_features = pd.read_excel('gsr_features.xlsx')\n",
    "gsr_features.rename(columns={'Unnamed: 0':'participant'}, inplace=True) # add name to first column\n",
    "# Pupillary Dilation PD\n",
    "pupil_features = pd.read_excel('pupil_features.xlsx')\n",
    "pupil_features.rename(columns={'Unnamed: 0':'participant'}, inplace=True)\n",
    "# Skin Temperature ST\n",
    "skintemp_features = pd.read_excel('skintemp_features.xlsx')\n",
    "skintemp_features.rename(columns={'Unnamed: 0':'participant'}, inplace=True)\n",
    "# X_all uses features from all signals\n",
    "X_all = pd.concat([gsr_features, pupil_features.iloc[:, 2::], skintemp_features.iloc[:, 2::]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.reset_option(\"max_columns\")\n",
    "#pd.set_option('max_columns', None)\n",
    "#pd.reset_option(\"min_rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = X_all\n",
    "df = dataset.copy()\n",
    "df2 = dataset.copy()\n",
    "# Apply min-max scaling on the unnormalised columns\n",
    "df = df.iloc[:, 2::]\n",
    "df = df.loc[:,df.mean()>1]\n",
    "df=(df-df.min())/(df.max()-df.min())\n",
    "for col in df.columns:\n",
    "    df2[col] = df[col]\n",
    "dataset = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>depr_label</th>\n",
       "      <th>min_normalised_gsr</th>\n",
       "      <th>max_normalised_gsr</th>\n",
       "      <th>mean_normalised_gsr</th>\n",
       "      <th>std_normalised_gsr</th>\n",
       "      <th>var_normalised_gsr</th>\n",
       "      <th>rms_normalised_gsr</th>\n",
       "      <th>min_filtered_gsr</th>\n",
       "      <th>max_filtered_gsr</th>\n",
       "      <th>...</th>\n",
       "      <th>second_diff_normalised_skintemp_abs_mean</th>\n",
       "      <th>first_diff_filtered_skintemp_abs_mean</th>\n",
       "      <th>second_diff_filtered_skintemp_abs_mean</th>\n",
       "      <th>num_normalised_skintemp_peaks</th>\n",
       "      <th>num_filtered_skintemp_peaks</th>\n",
       "      <th>vlp_skintemp_peak_occurrences</th>\n",
       "      <th>lp_skintemp_peak_occurrences</th>\n",
       "      <th>mean_vlp_skintemp_peak_amplitudes</th>\n",
       "      <th>mean_lp_skintemp_peak_amplitudes</th>\n",
       "      <th>ratio_skintemp_peak_occurrence_vlp_lp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.716610</td>\n",
       "      <td>0.970557</td>\n",
       "      <td>0.821910</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.825042</td>\n",
       "      <td>0.980664</td>\n",
       "      <td>1.405398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.071831</td>\n",
       "      <td>0.137465</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.166276</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553351</td>\n",
       "      <td>0.718968</td>\n",
       "      <td>0.630662</td>\n",
       "      <td>0.047855</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.632464</td>\n",
       "      <td>0.803887</td>\n",
       "      <td>0.975663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.329021</td>\n",
       "      <td>-0.064926</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.530042</td>\n",
       "      <td>0.873545</td>\n",
       "      <td>0.607463</td>\n",
       "      <td>0.073371</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>0.775245</td>\n",
       "      <td>1.096903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.234310</td>\n",
       "      <td>-0.013983</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.407362</td>\n",
       "      <td>0.515320</td>\n",
       "      <td>0.458619</td>\n",
       "      <td>0.030267</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.459610</td>\n",
       "      <td>0.652096</td>\n",
       "      <td>0.765979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420307</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307992</td>\n",
       "      <td>0.401229</td>\n",
       "      <td>0.353097</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.354137</td>\n",
       "      <td>0.543863</td>\n",
       "      <td>0.641232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.285511</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>p14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.689492</td>\n",
       "      <td>0.531518</td>\n",
       "      <td>0.050495</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>3.405516</td>\n",
       "      <td>3.776510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>p14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.508756</td>\n",
       "      <td>0.824976</td>\n",
       "      <td>0.599765</td>\n",
       "      <td>0.072180</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.604066</td>\n",
       "      <td>3.469690</td>\n",
       "      <td>4.094220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>-0.001051</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>p14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.574068</td>\n",
       "      <td>0.942852</td>\n",
       "      <td>0.709688</td>\n",
       "      <td>0.087339</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>3.590318</td>\n",
       "      <td>4.409810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>p14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.691630</td>\n",
       "      <td>0.969521</td>\n",
       "      <td>0.762679</td>\n",
       "      <td>0.058613</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.764914</td>\n",
       "      <td>3.831880</td>\n",
       "      <td>4.473302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>p14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.713401</td>\n",
       "      <td>0.852734</td>\n",
       "      <td>0.757124</td>\n",
       "      <td>0.034876</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.757922</td>\n",
       "      <td>3.956547</td>\n",
       "      <td>4.228696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.015378</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant  depr_label  min_normalised_gsr  max_normalised_gsr  \\\n",
       "0           p02           2            0.716610            0.970557   \n",
       "1           p02           2            0.553351            0.718968   \n",
       "2           p02           2            0.530042            0.873545   \n",
       "3           p02           2            0.407362            0.515320   \n",
       "4           p02           0            0.307992            0.401229   \n",
       "..          ...         ...                 ...                 ...   \n",
       "187         p14           2            0.478860            0.689492   \n",
       "188         p14           3            0.508756            0.824976   \n",
       "189         p14           3            0.574068            0.942852   \n",
       "190         p14           3            0.691630            0.969521   \n",
       "191         p14           3            0.713401            0.852734   \n",
       "\n",
       "     mean_normalised_gsr  std_normalised_gsr  var_normalised_gsr  \\\n",
       "0               0.821910            0.072007            0.005185   \n",
       "1               0.630662            0.047855            0.002290   \n",
       "2               0.607463            0.073371            0.005383   \n",
       "3               0.458619            0.030267            0.000916   \n",
       "4               0.353097            0.027189            0.000739   \n",
       "..                   ...                 ...                 ...   \n",
       "187             0.531518            0.050495            0.002550   \n",
       "188             0.599765            0.072180            0.005210   \n",
       "189             0.709688            0.087339            0.007628   \n",
       "190             0.762679            0.058613            0.003435   \n",
       "191             0.757124            0.034876            0.001216   \n",
       "\n",
       "     rms_normalised_gsr  min_filtered_gsr  max_filtered_gsr  ...  \\\n",
       "0              0.825042          0.980664          1.405398  ...   \n",
       "1              0.632464          0.803887          0.975663  ...   \n",
       "2              0.611853          0.775245          1.096903  ...   \n",
       "3              0.459610          0.652096          0.765979  ...   \n",
       "4              0.354137          0.543863          0.641232  ...   \n",
       "..                  ...               ...               ...  ...   \n",
       "187            0.533896          3.405516          3.776510  ...   \n",
       "188            0.604066          3.469690          4.094220  ...   \n",
       "189            0.715010          3.590318          4.409810  ...   \n",
       "190            0.764914          3.831880          4.473302  ...   \n",
       "191            0.757922          3.956547          4.228696  ...   \n",
       "\n",
       "     second_diff_normalised_skintemp_abs_mean  \\\n",
       "0                                    0.004944   \n",
       "1                                    0.005144   \n",
       "2                                    0.005573   \n",
       "3                                    0.004863   \n",
       "4                                    0.005788   \n",
       "..                                        ...   \n",
       "187                                  0.006883   \n",
       "188                                  0.007320   \n",
       "189                                  0.006555   \n",
       "190                                  0.006118   \n",
       "191                                  0.004484   \n",
       "\n",
       "     first_diff_filtered_skintemp_abs_mean  \\\n",
       "0                                 0.071831   \n",
       "1                                 0.001383   \n",
       "2                                 0.001172   \n",
       "3                                 0.001020   \n",
       "4                                 0.001512   \n",
       "..                                     ...   \n",
       "187                               0.001046   \n",
       "188                               0.001801   \n",
       "189                               0.001031   \n",
       "190                               0.001128   \n",
       "191                               0.001141   \n",
       "\n",
       "     second_diff_filtered_skintemp_abs_mean  num_normalised_skintemp_peaks  \\\n",
       "0                                  0.137465                       0.416667   \n",
       "1                                  0.002745                       0.333333   \n",
       "2                                  0.002322                       0.666667   \n",
       "3                                  0.002030                       0.666667   \n",
       "4                                  0.003005                       0.500000   \n",
       "..                                      ...                            ...   \n",
       "187                                0.002082                       0.416667   \n",
       "188                                0.003571                       0.500000   \n",
       "189                                0.002036                       0.500000   \n",
       "190                                0.002233                       0.500000   \n",
       "191                                0.002275                       0.333333   \n",
       "\n",
       "     num_filtered_skintemp_peaks  vlp_skintemp_peak_occurrences  \\\n",
       "0                            0.4                       0.333333   \n",
       "1                            0.3                       0.000000   \n",
       "2                            0.4                       0.333333   \n",
       "3                            0.2                       0.000000   \n",
       "4                            0.4                       0.333333   \n",
       "..                           ...                            ...   \n",
       "187                          0.3                       0.666667   \n",
       "188                          0.4                       0.666667   \n",
       "189                          0.4                       0.333333   \n",
       "190                          0.4                       0.333333   \n",
       "191                          0.2                       0.333333   \n",
       "\n",
       "     lp_skintemp_peak_occurrences  mean_vlp_skintemp_peak_amplitudes  \\\n",
       "0                        0.636364                           0.166276   \n",
       "1                        0.090909                           0.329021   \n",
       "2                        0.363636                           0.234310   \n",
       "3                        0.000000                           0.420307   \n",
       "4                        0.454545                           0.285511   \n",
       "..                            ...                                ...   \n",
       "187                      0.545455                           0.005077   \n",
       "188                      0.363636                           0.003171   \n",
       "189                      0.636364                           0.006459   \n",
       "190                      0.454545                           0.010085   \n",
       "191                      0.454545                           0.015378   \n",
       "\n",
       "     mean_lp_skintemp_peak_amplitudes  ratio_skintemp_peak_occurrence_vlp_lp  \n",
       "0                            0.002174                               0.200000  \n",
       "1                           -0.064926                               0.250000  \n",
       "2                           -0.013983                               0.285714  \n",
       "3                            0.010984                               0.333333  \n",
       "4                            0.008479                               0.250000  \n",
       "..                                ...                                    ...  \n",
       "187                         -0.000736                               0.333333  \n",
       "188                         -0.001051                               0.428571  \n",
       "189                         -0.000129                               0.200000  \n",
       "190                         -0.000088                               0.250000  \n",
       "191                          0.001840                               0.250000  \n",
       "\n",
       "[192 rows x 87 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df2\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define a customised neural network structure\n",
    "class TwoLayerNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_output)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave-one-participant-out method for cross-validation\n",
    "participants = np.unique(dataset['participant'].values)\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "for epoch_test in range(20,251,5):\n",
    "    acc = 0\n",
    "    for chosen in participants:\n",
    "        msk = dataset['participant'] == chosen\n",
    "        test_data = dataset[msk]\n",
    "        train_data = dataset[~msk]\n",
    "\n",
    "        num_features = train_data.shape[1] - 2\n",
    "\n",
    "        # split training data into input and target\n",
    "        # drop the first column (participant)\n",
    "        # the second column is target and the rest are features\n",
    "        train_data = train_data.drop(columns='participant')\n",
    "        train_input = train_data.iloc[:, 1:,]\n",
    "        train_target = train_data.iloc[:, :1:]\n",
    "\n",
    "        # split test data into input and target\n",
    "        # drop the first column (participant)\n",
    "        # the second column is target and the restare features\n",
    "        test_data = test_data.drop(columns='participant')\n",
    "        test_input = test_data.iloc[:, 1:,]\n",
    "        test_target = test_data.iloc[:, :1:]\n",
    "\n",
    "        # # create Tensors to hold inputs and outputs\n",
    "        X = torch.Tensor(train_input.values).float()\n",
    "        Y = torch.Tensor(train_target.values).long().squeeze()\n",
    "\n",
    "        # -- Train Model --\n",
    "        # define the number of inputs, classes, training epochs, and learning rate\n",
    "        input_neurons = X.shape[1]\n",
    "        hidden_neurons = 100\n",
    "        output_neurons = np.unique(Y).size\n",
    "        learning_rate = 0.002\n",
    "        weight_decay_rate = 0.001\n",
    "\n",
    "        # define a neural network using the customised structure \n",
    "        net = TwoLayerNet(input_neurons, hidden_neurons, output_neurons)\n",
    "\n",
    "        # define loss function (https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        # define optimiser (https://pytorch.org/docs/stable/optim.html)\n",
    "        optimiser = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay = weight_decay_rate)\n",
    "\n",
    "        # store all losses for visualisation\n",
    "        all_losses = []\n",
    "\n",
    "        # train a neural network\n",
    "        for epoch in range(epoch_test):\n",
    "            # Perform forward pass: compute predicted y by passing x to the model.\n",
    "            Y_pred = net(X)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_func(Y_pred, Y)\n",
    "            all_losses.append(loss.item())\n",
    "\n",
    "            # print progress\n",
    "            #if epoch % 50 == 0:\n",
    "            if epoch+1 == epoch_test:\n",
    "                # convert three-column predicted Y values to one column for comparison\n",
    "                _, predicted = torch.max(Y_pred, 1)\n",
    "\n",
    "                # calculate and print accuracy\n",
    "                total = predicted.size(0)\n",
    "                correct = predicted.data.numpy() == Y.data.numpy()\n",
    "                print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "                      % (epoch + 1, epoch_test, loss.item(), 100 * sum(correct)/total))\n",
    "\n",
    "            # Clear the gradients before running the backward pass.\n",
    "            net.zero_grad()\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimiser makes an update to its\n",
    "            # parameters\n",
    "            optimiser.step()\n",
    "\n",
    "        # -- Test Model --\n",
    "        # create Tensors to hold inputs and outputs\n",
    "        X_test = torch.Tensor(test_input.values).float()\n",
    "        Y_test = torch.Tensor(test_target.values).long().squeeze()\n",
    "\n",
    "\n",
    "        # Here, Y_pred_test contains three columns, where the index of the\n",
    "        # max column indicates the class of the instance\n",
    "        net.eval()\n",
    "        Y_pred_test = net(X_test)\n",
    "\n",
    "        # get prediction\n",
    "        # convert three-column predicted Y values to one column for comparison\n",
    "        _, predicted_test = torch.max(Y_pred_test, 1)\n",
    "\n",
    "        # calculate accuracy\n",
    "        total_test = predicted_test.size(0)\n",
    "        correct_test = sum(predicted_test.data.numpy() == Y_test.data.numpy())\n",
    "\n",
    "        #print('Testing Accuracy: %.2f %%' % (100 * correct_test / total_test))\n",
    "        acc += 100.0 * correct_test / total_test\n",
    "            \n",
    "    if acc >= best_acc:\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch_test\n",
    "        no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch': best_epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimiser_state_dict': optimiser.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, \"best_all.pt\")\n",
    "    elif acc <= best_acc:\n",
    "        no_improve += 1\n",
    "        if no_improve == 10:\n",
    "            break\n",
    "    print(acc/len(participants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.291666666666664\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "# All\n",
    "# 32.291666666666664\n",
    "# epoch 105\n",
    "# hidden_neurons = 100\n",
    "# learning_rate = 0.002\n",
    "# weight_decay_rate = 0.001\n",
    "\n",
    "# GSR\n",
    "# 32.8125\n",
    "# 205\n",
    "#        hidden_neurons = 100\n",
    "#        learning_rate = 0.001\n",
    "#        weight_decay_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "# Pupil\n",
    "# 32.8125\n",
    "# 125\n",
    "#        hidden_neurons = 100\n",
    "#        learning_rate = 0.001\n",
    "#        weight_decay_rate = 0.001\n",
    "\n",
    "# Skin Temp\n",
    "#35.9375\n",
    "#45\n",
    "#        hidden_neurons = 100\n",
    "#        learning_rate = 0.001\n",
    "#        weight_decay_rate = 0.001\n",
    "\n",
    "print(best_acc/12)\n",
    "print(best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the whole dataset as training set \n",
    "train_data = dataset\n",
    "test_data = dataset\n",
    "\n",
    "num_features = train_data.shape[1] - 2\n",
    "\n",
    "# split training data into input and target\n",
    "# drop the first column (participant)\n",
    "# the second column is target and the rest are features\n",
    "train_data = train_data.drop(columns='participant')\n",
    "train_input = train_data.iloc[:, 1:,]\n",
    "train_target = train_data.iloc[:, :1:]\n",
    "\n",
    "# split test data into input and target\n",
    "# drop the first column (participant)\n",
    "# the second column is target and the restare features\n",
    "test_data = test_data.drop(columns='participant')\n",
    "test_input = test_data.iloc[:, 1:,]\n",
    "test_target = test_data.iloc[:, :1:]\n",
    "\n",
    "# # create Tensors to hold inputs and outputs\n",
    "X = torch.Tensor(train_input.values).float()\n",
    "Y = torch.Tensor(train_target.values).long().squeeze()\n",
    "\n",
    "# -- Train Model --\n",
    "# define the number of inputs, classes, training epochs, and learning rate\n",
    "input_neurons = X.shape[1]\n",
    "hidden_neurons = 100\n",
    "output_neurons = np.unique(Y).size\n",
    "learning_rate = 0.002\n",
    "weight_decay_rate = 0.001\n",
    "num_epoch = 105\n",
    "\n",
    "# define a neural network using the customised structure \n",
    "net = TwoLayerNet(input_neurons, hidden_neurons, output_neurons)\n",
    "\n",
    "# define loss function (https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# define optimiser (https://pytorch.org/docs/stable/optim.html)\n",
    "optimiser = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay = weight_decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/105] Loss: 1.3919  Accuracy: 20.31 %\n",
      "Epoch [51/105] Loss: 1.1477  Accuracy: 48.44 %\n",
      "Epoch [101/105] Loss: 1.0142  Accuracy: 58.85 %\n"
     ]
    }
   ],
   "source": [
    "# store all losses for visualisation\n",
    "all_losses = []\n",
    "\n",
    "# train a neural network\n",
    "for epoch in range(num_epoch):\n",
    "    # Perform forward pass: compute predicted y by passing x to the model.\n",
    "    Y_pred = net(X)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_func(Y_pred, Y)\n",
    "    all_losses.append(loss.item())\n",
    "\n",
    "    # print progress\n",
    "    if epoch % 50 == 0:\n",
    "        # convert three-column predicted Y values to one column for comparison\n",
    "        _, predicted = torch.max(Y_pred, 1)\n",
    "\n",
    "        # calculate and print accuracy\n",
    "        total = predicted.size(0)\n",
    "        correct = predicted.data.numpy() == Y.data.numpy()\n",
    "\n",
    "        print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "              % (epoch + 1, num_epoch, loss.item(), 100 * sum(correct)/total))\n",
    "\n",
    "    # Clear the gradients before running the backward pass.\n",
    "    net.zero_grad()\n",
    "\n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimiser makes an update to its\n",
    "    # parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for testing:\n",
      "[[33  3  7  5]\n",
      " [ 7 28  7  6]\n",
      " [ 7  7 28  6]\n",
      " [ 3  8  8 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.660     0.688     0.673        48\n",
      "           1      0.609     0.583     0.596        48\n",
      "           2      0.560     0.583     0.571        48\n",
      "           3      0.630     0.604     0.617        48\n",
      "\n",
      "    accuracy                          0.615       192\n",
      "   macro avg      0.615     0.615     0.614       192\n",
      "weighted avg      0.615     0.615     0.614       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "model=net\n",
    "# -- Test Model --\n",
    "# create Tensors to hold inputs and outputs\n",
    "X_test = torch.Tensor(test_input.values).float()\n",
    "Y_test = torch.Tensor(test_target.values).long().squeeze()\n",
    "\n",
    "\n",
    "# Here, Y_pred_test contains three columns, where the index of the\n",
    "# max column indicates the class of the instance\n",
    "net.eval()\n",
    "Y_pred_test = model(X_test)\n",
    "\n",
    "# get prediction\n",
    "# convert three-column predicted Y values to one column for comparison\n",
    "_, predicted_test = torch.max(Y_pred_test, 1)\n",
    "\n",
    "print('Confusion matrix for testing:')\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(Y_test, predicted_test))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(Y_test, predicted_test, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80, 21,  1,  3, 18,  2,  5, 82, 23, 20, 48,  0, 64, 58, 62, 67, 17,\n",
       "       44, 79, 83, 81, 61, 34, 63, 72, 36, 16, 78, 35, 31, 57, 71, 84, 59,\n",
       "       22, 73, 69, 65, 70, 33, 68, 19, 32, 45, 49, 38,  8,  7, 41, 37, 11,\n",
       "       39, 24,  6, 50, 46,  4, 26, 52, 25, 51, 54,  9, 60, 28, 75, 47, 77,\n",
       "       12, 13, 40, 74, 27, 76, 43, 15, 53, 10, 66, 30, 56, 42, 14, 29, 55],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement magniture measure (Gedeon 1996)\n",
    "w_ih = model.fc1.weight.detach().numpy()\n",
    "w_ho = model.fc2.weight.detach().numpy()\n",
    "\n",
    "# Contribution of input neurons to hidden neurons P_ij\n",
    "denominator = np.zeros(w_ih.shape[0])\n",
    "P_ij = np.zeros(w_ih.shape)\n",
    "for i in range(w_ih.shape[0]):\n",
    "    denominator[i] = np.abs(w_ih[i]).sum()\n",
    "for i in range(w_ih.shape[0]):\n",
    "    for j in range(w_ih.shape[1]):\n",
    "        P_ij[i][j] = np.abs(w_ih[i][j]) / denominator[i]\n",
    "        \n",
    "# Contribution of hidden neurons to output neurons P_jk\n",
    "denominator = np.zeros(w_ho.shape[0])\n",
    "P_jk = np.zeros(w_ho.shape)\n",
    "for i in range(w_ho.shape[0]):\n",
    "    denominator[i] = np.abs(w_ho[i]).sum()\n",
    "for j in range(w_ho.shape[0]):\n",
    "    for k in range(w_ho.shape[1]):\n",
    "        P_jk[j][k] = np.abs(w_ho[j][k]) / denominator[j]\n",
    "\n",
    "# Contribution of input neurons to output neurons Q_ik\n",
    "Q_ik = np.zeros((w_ih.shape[1], w_ho.shape[0]))\n",
    "for i in range(w_ih.shape[1]):\n",
    "    for k in range(w_ho.shape[0]):\n",
    "        for j in range(w_ih.shape[0]):\n",
    "            Q_ik[i][k] += P_ij[j][i] * P_jk[k][j]\n",
    "\n",
    "# Average the contribution of inputs to the 4 outputs and sort\n",
    "indices = np.argsort(Q_ik.mean(axis=1)) # sorts in ascending order\n",
    "indices = indices[::-1] # reverse order\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 86)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_dataset = dataset.drop(dataset.columns[indices[0:1]+2],axis=1)\n",
    "reduced_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000882  , 0.00091618, 0.00119703, 0.00143524, 0.00148655,\n",
       "       0.00167246, 0.00168316, 0.00200719, 0.00206511, 0.00235712,\n",
       "       0.00260868, 0.00412627, 0.00415134, 0.00463504, 0.00488084,\n",
       "       0.00560188, 0.00590604, 0.00671563, 0.00752657, 0.00852674,\n",
       "       0.00863305, 0.00904913, 0.00907952, 0.0091086 , 0.00914183,\n",
       "       0.00918801, 0.0092986 , 0.00985623, 0.01004246, 0.01024394,\n",
       "       0.01037789, 0.01062007, 0.01101012, 0.01147492, 0.01149516,\n",
       "       0.01150054, 0.01165786, 0.01176584, 0.01200296, 0.01212736,\n",
       "       0.01240817, 0.01244799, 0.01246869, 0.01265293, 0.01280557,\n",
       "       0.01286068, 0.01311283, 0.01311354, 0.01356399, 0.01369795,\n",
       "       0.01377556, 0.01396119, 0.01413979, 0.014143  , 0.01460754,\n",
       "       0.01478413, 0.01487308, 0.01492236, 0.01516813, 0.0152959 ,\n",
       "       0.01548404, 0.01552629, 0.01557279, 0.01601912, 0.01602615,\n",
       "       0.01661305, 0.01663975, 0.01684631, 0.01695522, 0.01722234,\n",
       "       0.01747641, 0.01752861, 0.01753505, 0.01757474, 0.01760593,\n",
       "       0.01791547, 0.01805455, 0.01855602, 0.01862393, 0.01873712,\n",
       "       0.01975944, 0.02045756, 0.02116846, 0.02134595, 0.02189755])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(Q_ik.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2514eed3c48>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXk0lEQVR4nO3df4zc9Z3f8ed7dzEHafgRh144/8Ag07QY6Xr2nuP2qlNJGgo9X40EkX1JG1QRIZ2MLq16qpJKsVLUSEGqkqYNjeoDLgEl5SLuorNSONo7qNSrMOfd8sfFpNFtHftYTAuYhaJAYnb33T/mO+a7X8/OzJrdne/M9/mQIu/3O9/55juj4fv6fj8/3t/ITCRJzTM26AOQJA2GASBJDWUASFJDGQCS1FAGgCQ11MSgD2AlPvjBD+a2bdsGfRiSNFSmp6dfzcyrquuHKgC2bdvG1NTUoA9DkoZKRJzqtN4mIElqKANAkhrKAJCkhjIAJKmhDABJaigDQJIaygCQpBqbPjXH/U/PMH1qbtX3PVTzACSpSaZPzfGpB45ydn6RDRNjfPsze9h1zZWrtn/vACSppo6eOMPZ+UUWE96ZX+ToiTOrun8DQJJqas91G9kwMcZ4wEUTY+y5buOq7t8mIEmqqV3XXMm3P7OHoyfOsOe6java/AMGgCTVzvSpuSUn/dU+8bcZAJJUI2vd8VtmH4AkDVh5qOdad/yWeQcgSQNUveI/tHcHGybGeGd+cU06fssMAEkaoOoV/9xbZ9e047fMAJCkAWoP9Sxf8a9lx2+ZASBJA7TWQz27MQAkacDW64q/ylFAktRQBoAkrbO1rPC5EjYBSdI6Ws+JXr14ByBJ62g9J3r10lcARMQtEfGjiJiJiM91eP3iiPi94vVnI2Jbsf7jETEdEX9e/PvR0nt2FetnIuLfRUSs1oeSpLpa6wqfK9GzCSgixoH7gY8Ds8CxiDiSmc+XNrsLmMvM7RFxALgP2A+8Cvx6Zp6OiBuBJ4FNxXu+AdwNHAUeB24BnlidjyVJ9TTIYZ9V/fQB7AZmMvMEQEQ8CuwDygGwD/hi8fdjwNcjIjLzudI2x4Gfi4iLgQ8Al2XmM8U+HwZuwwCQ1ACDGvZZ1U8T0CbghdLyLO9exZ+3TWbOA28A1fua24HnMvNnxfazPfYJQETcHRFTETH1yiuv9HG4klQ/dRn5U9bPHUCntvlcyTYRsYNWs9DNK9hna2XmYeAwwOTkZMdtJKnO6jTyp6yfO4BZYEtpeTNwerltImICuBx4rVjeDHwP+HRm/u/S9pt77FOSRkKdRv6U9RMAx4DrI+LaiNgAHACOVLY5AtxZ/H0H8FRmZkRcAfxn4POZ+T/aG2fmS8CbEbGnGP3zaeAP3+NnkaRaqtPIn7KeTUCZOR8R99AawTMOPJSZxyPiXmAqM48ADwKPRMQMrSv/A8Xb7wG2A1+IiC8U627OzJeB3wS+CVxCq/PXDmBJI6lOI3/KInN4mtUnJydzampq0IchSUMlIqYzc7K63pnAktRQBoAkNZQBIEkNZQBIUkMZAJK0Buo487fK5wFI0iqZPjXH0RNnuPLSDdz7/eO1m/lbZQBI0gVqn/DbE7va5R7GIljMXDLz1wCQpBFRre9z+87N58o9kMnYWBBkrWb+VhkAknQBqvV9EtgwMcY784tcNDHGob07mHvrbK1m/lYZAJJ0Adr1fdon/Nt3bub2nZtrV+6hGwNAkvpUbvNfrr7PMJz42wwASerDcjX9h+mEX2UASFIX7av+06+/fV5N/2E++YMBIEnLKl/1T4wFE+NjLCws1npkz0oYAJK0jPJIn4XFZP/uLWy64pKh6eTtxQCQNPKqnbfVCVzLvdZppM8onPjbDABJI2m5sgyH9u44tzwxFhDB/ML5r7U7euv4JK/VYgBIGjnltvtqWYYnfvDSu525CwkkSYfXio7egzdtH7kTf5vVQCWNhHL1zXLb/eJiMhZx7oHst9549bsPaB8PLio9rH3JayPS0duNdwCShl51jP6hvTu6lmX48Ifev2wfQPm1Ub3ybzMAJA29al2eubfOdm27r07gqv496if+NgNA0lDqNlqnfdJvyon8QhkAkoZGtweujPJonbViAEgaCt1G9oz6aJ21YgBIqo1uE7bK7fzD8sCVujMAJNVCp5E81Qlcw/bAlbozACTVQnUkT3VSVq+RPVo5A0BSLVRH8tx649UcO/maI3vWkAEgqRY6PWGrSZOyBsEAkDRQ1Y7fpk7KGgQDQNK6qpZi7vSYRa0PA0DSuqmO9Ll95+aRe8ziMLEaqKR1Ux3pk9Co6pt14x2ApHXT6Qlbt+/cbEfvgBgAklZdtxm9ncbye+IfDANA0nvWrWO302MWD960fcBHLDAAJF2g5SpzVjt2Oz1m0Sv+ejAAJK1Yt8qc7Y7dbjN6VQ99BUBE3AJ8DRgHHsjML1devxh4GNgFnAH2Z+bJiNgIPAb8MvDNzLyn9J7/BlwNvF2sujkzX35vH0fSWum3Mmenjl1n9NZTzwCIiHHgfuDjwCxwLCKOZObzpc3uAuYyc3tEHADuA/YDPwW+ANxY/K/qU5k59R4/g6Q1ttJn7kJzH7M4TPq5A9gNzGTmCYCIeBTYB5QDYB/wxeLvx4CvR0Rk5k+AP40Ie3ykIVDtzO10xW9lztHRTwBsAl4oLc8CH1lum8ycj4g3gI3Aqz32/bsRsQD8PvCvMzOrG0TE3cDdAFu3bu3jcCX1a7nROxNjARHML3S+4rcy52joJwCiw7rqibqfbao+lZkvRsT7aQXAP6bVj7B0J5mHgcMAk5OTvfYpqU9dyzIsJJAkXvGPsn4CYBbYUlreDJxeZpvZiJgALgde67bTzHyx+PfNiPgOraam8wJA0upqX/Wffv3tjmUZ3plfZLy4A1hY8Ip/lPUTAMeA6yPiWuBF4ADwyco2R4A7gWeAO4CnOjXntBUhcUVmvhoRFwF7gT++gOOXtALlq/6JsWBifOzcSb46egfwin/E9QyAok3/HuBJWsNAH8rM4xFxLzCVmUeAB4FHImKG1pX/gfb7I+IkcBmwISJuA24GTgFPFif/cVon/99Z1U8m6TzlztyFxWT/7i1suuKSrqN3NLr6mgeQmY8Dj1fWHSr9/VPgE8u8d9syu93V3yFKWi2dirF5km8uZwJLI6ZbIbZOj11UcxkA0gjpNGGrWojNzly1GQDSCFhuZI+F2NSNASANuW4jeyzEpm4MAGkIdGvX7zWyx0JsWo4BINVcr3b9apmG6sge2/y1HANAqql+2/Ut06ALZQBINbTSdn2v8nUhDACphmzX13owAKQa6jVj1yt+rQYDQBqg5R7A4oxdrQcDQBqQajt/+QEsztjVejAApHW03Pj96gNYnLGr9WAASGtouUcuVsfvd3oAi7TWDABplbVP+ldeumHJhK0lj1zsMH4ffACL1pcBIK2icrv+WASLmR0fubjc+H1P/FpPBoC0Qv3W5SGTsbEgyI6PXPRkr0EzAKQ+LNes06suz6G9O5h76+yyj1yUBskAkHro1qxjXR4NMwNA6qDfZh3r8miYGQBSoVszT7dmHevyaFgZABLdm3l6Net4xa9hZQBI0LWZx2YdjSoDQI1VbuevVt/sNHpHGjUGgBqjW1mGb39mj6N31DgGgIZat0lZ5eVeZRmOnjjDwZu2e+JXoxgAGlr9PCy9vdxPWQapaQwADa0l5ZQ7TMoqL1uWQTqfAaChVe24rU7Kqi5blkFaygDQ0Or02MTqpCwnaUnLi8wc9DH0bXJyMqempgZ9GBqwakevpO4iYjozJ6vrvQPQUKl2/LafnStp5cYGfQDSSlQ7fo+eODPoQ5KGlncAqr1uM3YdvildOANAtdapyccZu9LqMABUa52afJyxK60OA0C1VC7hYJOPtDYMANVCt0JtVuaU1kZfARARtwBfA8aBBzLzy5XXLwYeBnYBZ4D9mXkyIjYCjwG/DHwzM+8pvWcX8E3gEuBx4LM5TJMStGqq7fzVQm1zb53l4E3bB32Y0sjpOQw0IsaB+4FbgRuA34iIGyqb3QXMZeZ24KvAfcX6nwJfAH67w66/AdwNXF/875YL+QAaTtOn5rj/6ZlzV/7lE367UNt4YLOPtIb6uQPYDcxk5gmAiHgU2Ac8X9pmH/DF4u/HgK9HRGTmT4A/jYgll28RcTVwWWY+Uyw/DNwGPPEePouGRKcqnuV2fgu1SeujnwDYBLxQWp4FPrLcNpk5HxFvABuBV7vsc7ayz02dNoyIu2ndKbB169Y+Dld11b7aP/362+c18XQa2umJX1pb/QRAdFhXbavvZ5sL2j4zDwOHoVULqMs+VWPlq/6JsWBifIyFhUWfuSsNUD8BMAtsKS1vBk4vs81sREwAlwOv9djn5h771Agpt/MvLCb7d29h0xWX2MQjDVA/AXAMuD4irgVeBA4An6xscwS4E3gGuAN4qtuInsx8KSLejIg9wLPAp4F/fwHHryFRLeFw+87NnvilAesZAEWb/j3Ak7SGgT6Umccj4l5gKjOPAA8Cj0TEDK0r/wPt90fESeAyYENE3AbcnJnPA7/Ju8NAn8AO4JHWqXa/pMHyeQBaM9btl+rB5wFoTVRP8uUSDuUHtFu3X6ofA0DnWe6k3p6Q1a1kQ/ukPxbBYuaSIm4GgFQvBoCW6DRJq31SnxgLiGB+oXPJhid+8NK5ZTIZGwuCdDavVFMGgJaolmUon9TfWUggSZaWbGiP7Ln1xqs5dvK1c8sWcZPqzQDQEtXhmuWT+nhxB9CewNWpZMOHP/R+O36lIWEA6Lw2/+pwzfJJHehassEZvdLwMAAaqtdonW4ndU/w0mgwABqo3NHraB2puQyABip39DpaR2ouA6CBqh29jtaRmskAaCDr8kgCA6CxHK0jqeczgSVJo8kAkKSGMgAkqaEMgIaYPjXH/U/PMH1qbtCHIqkm7ARugGqFT2vzSwLvABqhWuHz6Ikzgz4kSTVgADRAe+LXeOBsX0nn2ATUAE78ktSJAdAQTvySVGUTkCQ1lAEgSQ1lAIwwx/5L6sY+gBHl2H9JvXgHMKIc+y+pFwNgRDn2X1IvNgGNKMf+S+rFABhhjv2X1I1NQJLUUAaAJDWUATBCHPcvaSXsAxgRjvuXtFLeAYwIx/1LWinvAIbY9Km5c8M82+P+35lfdNy/pL4YAEOqU5OP4/4lrYQBMKQ6NfkcvGm7J35JfbMPYEhZ6kHSe9XXHUBE3AJ8DRgHHsjML1devxh4GNgFnAH2Z+bJ4rXPA3cBC8BvZeaTxfqTwJvF+vnMnFyFz9MYlnqQ9F71DICIGAfuBz4OzALHIuJIZj5f2uwuYC4zt0fEAeA+YH9E3AAcAHYAvwD8cUT8tcxcKN53U2a+uoqfp1Es9SDpveinCWg3MJOZJzLzLPAosK+yzT7gW8XfjwEfi4go1j+amT/LzB8DM8X+dIGc7CVptfTTBLQJeKG0PAt8ZLltMnM+It4ANhbrj1beu6n4O4H/EhEJ/MfMPNzp/zwi7gbuBti6dWsfhzu6nOwlaTX1cwcQHdZln9t0e++vZOZO4FbgYET8aqf/88w8nJmTmTl51VVX9XG4o8vJXpJWUz8BMAtsKS1vBk4vt01ETACXA691e29mtv99GfgeNg11VG7yceSPpNXUTxPQMeD6iLgWeJFWp+4nK9scAe4EngHuAJ7KzIyII8B3IuIrtDqBrwf+LCLeB4xl5pvF3zcD967KJxohTvaStJZ6BkDRpn8P8CStYaAPZebxiLgXmMrMI8CDwCMRMUPryv9A8d7jEfFd4HlgHjiYmQsR8fPA91r9xEwA38nMP1qDzzfUnOwlaS31NQ8gMx8HHq+sO1T6+6fAJ5Z575eAL1XWnQB+caUH2zTW95G0liwFUQPlom7AkiYem3wkrRUDYMDK7fwTYwERzC8sHebpiV/SWrAW0IAtaedfSN5xmKekdeIdwICV2/nHizuAhQXb/CWtPQNgwKrt/IBt/pLWhQFQA9V2fk/8ktaDfQCS1FAGgCQ1lAEgSQ1lAEhSQxkAktRQBoAkNZQBIEkNZQBIUkMZAJLUUAbAAJQf8yhJg2IpiHXW6TGPln6QNAgGwDppP/Tl9Otvn/eYRwNA0iAYAOug+tCXifExSz5LGjgDYB2UH/qysJjs372FTVdcYslnSQNlAKyS8nN9d11z5ZLl6sPdb9+52RO/pIEzAFZBtWP30N4d3Pv940s6en24u6S6MQBWwZLn+s4v8sQPXjqvo/fgTds98UuqFecBrEB1/H57+cpLN7BhYozxgIsmxrj1xquXLNvRK6mOvAPoU69mnkN7dzD31tlzTTwf/tD7bfKRVGsGQBfljtxezTxzb53l4E3bz723+pxfSaobA6CifdK/8tIN513hl0fy3Hrj1Rw7+dq5ZZt5JA0bA6Ck3MwzFsFi5pIr/OpIHpt5JA2zxgfAcs08ZDI2FgR57gq/2qxjM4+kYdboAOjUsVtu5ql27ErSKGl0AFQ7djs180jSqGpEACxXpqE9fr/ckWuzjqSmGPkAWOn4fUlqipEPgJWO35ekphj5UhDtSpyWaZCkpUb+DmDXNVc6fl+SOhj5AIDzx+vb0StJDWgCkiR11lcARMQtEfGjiJiJiM91eP3iiPi94vVnI2Jb6bXPF+t/FBF/v999SpLWVs8AiIhx4H7gVuAG4Dci4obKZncBc5m5HfgqcF/x3huAA8AO4BbgP0TEeJ/7lCStoX7uAHYDM5l5IjPPAo8C+yrb7AO+Vfz9GPCxiIhi/aOZ+bPM/DEwU+yvn31KktZQPwGwCXihtDxbrOu4TWbOA28AG7u8t599AhARd0fEVERMvfLKK30criSpH/0EQHRYl31us9L156/MPJyZk5k5edVVV3U9UElS//oZBjoLbCktbwZOL7PNbERMAJcDr/V4b699nmd6evrViDjVxzF38kHg1Qt8bxP4/fTmd9Sd309vg/qOrum0sp8AOAZcHxHXAi/S6tT9ZGWbI8CdwDPAHcBTmZkRcQT4TkR8BfgF4Hrgz2jdAfTa53ky84JvASJiKjMnL/T9o87vpze/o+78fnqr23fUMwAycz4i7gGeBMaBhzLzeETcC0xl5hHgQeCRiJihdeV/oHjv8Yj4LvA8MA8czMwFgE77XP2PJ0laTmR2bHofOXVL3rrx++nN76g7v5/e6vYdNWkm8OFBH0DN+f305nfUnd9Pb7X6jhpzByBJWqpJdwCSpBIDQJIaauQDwKJz54uILRHxdET8MCKOR8Rni/UfiIj/GhF/Ufzb6JrZRd2q5yLi+8XytUWxw78oih9uGPQxDlJEXBERj0XE/yp+S3/L39C7IuKfFf99/SAi/lNE/FzdfkMjHQAWnVvWPPDPM/NvAHuAg8X38jngTzLzeuBPiuUm+yzww9LyfcBXi+9njlYRxCb7GvBHmfnXgV+k9V35GwIiYhPwW8BkZt5Ia7j7AWr2GxrpAMCicx1l5kuZ+T+Lv9+k9R/uJpYW9fsWcNtgjnDwImIz8GvAA8VyAB+lVewQ/H4uA36V1hwgMvNsZr6Ov6GyCeCSojrCpcBL1Ow3NOoB0HfRuaYqnt3wS8CzwM9n5kvQCgngrw7uyAbu3wL/AlgsljcCrxfFDsHf0nXAK8DvFs1kD0TE+/A3BEBmvgj8G+AvaZ343wCmqdlvaNQDoO+ic00UEX8F+H3gn2bm/xv08dRFROwFXs7M6fLqDps2+bc0AewEvpGZvwT8hIY293RS9H3sA66lVQbnfbSaoqsG+hsa9QDop5BdI0XERbRO/t/OzD8oVv/fiLi6eP1q4OVBHd+A/QrwDyPiJK1mw4/SuiO4oridB39Ls8BsZj5bLD9GKxD8DbX8PeDHmflKZr4D/AHwt6nZb2jUA+BcIbuit/0ArcJ1jVa0Zz8I/DAzv1J6qV3Uj+LfP1zvY6uDzPx8Zm7OzG20fjNPZeangKdpFTuEBn8/AJn5f4AXIuLDxaqP0ar55W+o5S+BPRFxafHfW/v7qdVvaORnAkfEP6B19dYuOvelAR/SwEXE3wH+O/DnvNvG/S9p9QN8F9hK6wf8icx8bSAHWRMR8XeB387MvRFxHa07gg8AzwH/KDN/NsjjG6SI+Ju0Osk3ACeAf0LrotLfEBAR/wrYT2vU3XPAZ2i1+dfmNzTyASBJ6mzUm4AkScswACSpoQwASWooA0CSGsoAkKSGMgAkqaEMAElqqP8PZETmppd/K+MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(Q_ik.mean(axis=1)),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0+2, 1+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "i = 1\n",
      "i = 2\n",
      "i = 3\n",
      "i = 4\n"
     ]
    }
   ],
   "source": [
    "# store all losses for visualisation\n",
    "all_acc = []\n",
    "for i in range(0,5):\n",
    "    for j in range(0,1):\n",
    "        cols = np.array([i+2])\n",
    "        reduced_dataset = dataset.drop(dataset.columns[cols],axis=1)\n",
    "        print(\"i = {}\".format(i))\n",
    "        # leave-one-participant-out method for cross-validation\n",
    "        participants = np.unique(reduced_dataset['participant'].values)\n",
    "        best_acc = 0\n",
    "        best_epoch = 0\n",
    "        for epoch_test in range(10,201,5):\n",
    "            acc = 0\n",
    "            for chosen in participants:\n",
    "                msk = reduced_dataset['participant'] == chosen\n",
    "                test_data = reduced_dataset[msk]\n",
    "                train_data = reduced_dataset[~msk]\n",
    "\n",
    "                num_features = train_data.shape[1] - 2\n",
    "\n",
    "                # split training data into input and target\n",
    "                # drop the first column (participant)\n",
    "                # the second column is target and the rest are features\n",
    "                train_data = train_data.drop(columns='participant')\n",
    "                train_input = train_data.iloc[:, 1:,]\n",
    "                train_target = train_data.iloc[:, :1:]\n",
    "\n",
    "                # split test data into input and target\n",
    "                # drop the first column (participant)\n",
    "                # the second column is target and the restare features\n",
    "                test_data = test_data.drop(columns='participant')\n",
    "                test_input = test_data.iloc[:, 1:,]\n",
    "                test_target = test_data.iloc[:, :1:]\n",
    "\n",
    "                # # create Tensors to hold inputs and outputs\n",
    "                X = torch.Tensor(train_input.values).float()\n",
    "                Y = torch.Tensor(train_target.values).long().squeeze()\n",
    "\n",
    "                # -- Train Model --\n",
    "                # define the number of inputs, classes, training epochs, and learning rate\n",
    "                input_neurons = X.shape[1]\n",
    "                hidden_neurons = 100\n",
    "                output_neurons = np.unique(Y).size\n",
    "                learning_rate = 0.002\n",
    "                weight_decay_rate = 0.001\n",
    "\n",
    "                # define a neural network using the customised structure \n",
    "                net = TwoLayerNet(input_neurons, hidden_neurons, output_neurons)\n",
    "\n",
    "                # define loss function (https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "                loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "                # define optimiser (https://pytorch.org/docs/stable/optim.html)\n",
    "                optimiser = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay = weight_decay_rate)\n",
    "\n",
    "                # store all losses for visualisation\n",
    "                all_losses = []\n",
    "\n",
    "                # train a neural network\n",
    "                for epoch in range(epoch_test):\n",
    "                    # Perform forward pass: compute predicted y by passing x to the model.\n",
    "                    Y_pred = net(X)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = loss_func(Y_pred, Y)\n",
    "                    all_losses.append(loss.item())\n",
    "\n",
    "                    # print progress\n",
    "                    #if epoch % 50 == 0:\n",
    "                    if epoch+1 == epoch_test:\n",
    "                        # convert three-column predicted Y values to one column for comparison\n",
    "                        _, predicted = torch.max(Y_pred, 1)\n",
    "\n",
    "                        # calculate and print accuracy\n",
    "                        total = predicted.size(0)\n",
    "                        correct = predicted.data.numpy() == Y.data.numpy()\n",
    "                        #print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%' % (epoch + 1, epoch_test, loss.item(), 100 * sum(correct)/total))\n",
    "\n",
    "                    # Clear the gradients before running the backward pass.\n",
    "                    net.zero_grad()\n",
    "\n",
    "                    # Perform backward pass\n",
    "                    loss.backward()\n",
    "\n",
    "                    # Calling the step function on an Optimiser makes an update to its\n",
    "                    # parameters\n",
    "                    optimiser.step()\n",
    "\n",
    "                # -- Test Model --\n",
    "                # create Tensors to hold inputs and outputs\n",
    "                X_test = torch.Tensor(test_input.values).float()\n",
    "                Y_test = torch.Tensor(test_target.values).long().squeeze()\n",
    "\n",
    "\n",
    "                # Here, Y_pred_test contains three columns, where the index of the\n",
    "                # max column indicates the class of the instance\n",
    "                net.eval()\n",
    "                Y_pred_test = net(X_test)\n",
    "\n",
    "                # get prediction\n",
    "                # convert three-column predicted Y values to one column for comparison\n",
    "                _, predicted_test = torch.max(Y_pred_test, 1)\n",
    "\n",
    "                # calculate accuracy\n",
    "                total_test = predicted_test.size(0)\n",
    "                correct_test = sum(predicted_test.data.numpy() == Y_test.data.numpy())\n",
    "\n",
    "                #print('Testing Accuracy: %.2f %%' % (100 * correct_test / total_test))\n",
    "                acc += 100.0 * correct_test / total_test\n",
    "\n",
    "            if acc >= best_acc:\n",
    "                best_acc = acc\n",
    "                best_epoch = epoch_test\n",
    "                no_improve = 0\n",
    "        #         torch.save({\n",
    "        #             'epoch': best_epoch,\n",
    "        #             'model_state_dict': net.state_dict(),\n",
    "        #             'optimiser_state_dict': optimiser.state_dict(),\n",
    "        #             'loss': loss,\n",
    "        #             }, \"best_all.pt\")\n",
    "            elif acc <= best_acc:\n",
    "                no_improve += 1\n",
    "                if no_improve == 7:\n",
    "                    all_acc.append(best_acc)\n",
    "                    break\n",
    "            #print(\"epoch num = {}\".format(epoch_test))\n",
    "            #print(\"avg accuracy = {}\".format(acc/len(participants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31.77083333, 31.77083333, 32.29166667, 32.29166667, 32.29166667])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(all_acc,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31.77083333, 32.8125    , 31.25      , 32.29166667, 30.20833333,\n",
       "       32.29166667, 30.72916667, 32.29166667, 30.72916667, 33.85416667])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(all_acc,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.166666666666668\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(best_acc/12)\n",
    "print(best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the whole dataset as training set \n",
    "train_data = reduced_dataset\n",
    "test_data = reduced_dataset\n",
    "\n",
    "num_features = train_data.shape[1] - 2\n",
    "\n",
    "# split training data into input and target\n",
    "# drop the first column (participant)\n",
    "# the second column is target and the rest are features\n",
    "train_data = train_data.drop(columns='participant')\n",
    "train_input = train_data.iloc[:, 1:,]\n",
    "train_target = train_data.iloc[:, :1:]\n",
    "\n",
    "# split test data into input and target\n",
    "# drop the first column (participant)\n",
    "# the second column is target and the restare features\n",
    "test_data = test_data.drop(columns='participant')\n",
    "test_input = test_data.iloc[:, 1:,]\n",
    "test_target = test_data.iloc[:, :1:]\n",
    "\n",
    "# # create Tensors to hold inputs and outputs\n",
    "X = torch.Tensor(train_input.values).float()\n",
    "Y = torch.Tensor(train_target.values).long().squeeze()\n",
    "\n",
    "# -- Train Model --\n",
    "# define the number of inputs, classes, training epochs, and learning rate\n",
    "input_neurons = X.shape[1]\n",
    "hidden_neurons = 100\n",
    "output_neurons = np.unique(Y).size\n",
    "learning_rate = 0.002\n",
    "weight_decay_rate = 0.001\n",
    "num_epoch = 10\n",
    "\n",
    "# define a neural network using the customised structure \n",
    "net = TwoLayerNet(input_neurons, hidden_neurons, output_neurons)\n",
    "\n",
    "# define loss function (https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# define optimiser (https://pytorch.org/docs/stable/optim.html)\n",
    "optimiser = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay = weight_decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 1.3879  Accuracy: 25.52 %\n"
     ]
    }
   ],
   "source": [
    "# store all losses for visualisation\n",
    "all_losses = []\n",
    "\n",
    "# train a neural network\n",
    "for epoch in range(num_epoch):\n",
    "    # Perform forward pass: compute predicted y by passing x to the model.\n",
    "    Y_pred = net(X)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_func(Y_pred, Y)\n",
    "    all_losses.append(loss.item())\n",
    "\n",
    "    # print progress\n",
    "    if epoch % 50 == 0:\n",
    "        # convert three-column predicted Y values to one column for comparison\n",
    "        _, predicted = torch.max(Y_pred, 1)\n",
    "\n",
    "        # calculate and print accuracy\n",
    "        total = predicted.size(0)\n",
    "        correct = predicted.data.numpy() == Y.data.numpy()\n",
    "\n",
    "        print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "              % (epoch + 1, num_epoch, loss.item(), 100 * sum(correct)/total))\n",
    "\n",
    "    # Clear the gradients before running the backward pass.\n",
    "    net.zero_grad()\n",
    "\n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimiser makes an update to its\n",
    "    # parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for testing:\n",
      "[[18 14  3 13]\n",
      " [ 5 26  1 16]\n",
      " [10 10  7 21]\n",
      " [ 3 16  1 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.375     0.429        48\n",
      "           1      0.394     0.542     0.456        48\n",
      "           2      0.583     0.146     0.233        48\n",
      "           3      0.359     0.583     0.444        48\n",
      "\n",
      "    accuracy                          0.411       192\n",
      "   macro avg      0.459     0.411     0.391       192\n",
      "weighted avg      0.459     0.411     0.391       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "model=net\n",
    "# -- Test Model --\n",
    "# create Tensors to hold inputs and outputs\n",
    "X_test = torch.Tensor(test_input.values).float()\n",
    "Y_test = torch.Tensor(test_target.values).long().squeeze()\n",
    "\n",
    "\n",
    "# Here, Y_pred_test contains three columns, where the index of the\n",
    "# max column indicates the class of the instance\n",
    "net.eval()\n",
    "Y_pred_test = model(X_test)\n",
    "\n",
    "# get prediction\n",
    "# convert three-column predicted Y values to one column for comparison\n",
    "_, predicted_test = torch.max(Y_pred_test, 1)\n",
    "\n",
    "print('Confusion matrix for testing:')\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(Y_test, predicted_test))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(Y_test, predicted_test, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net\n",
    "optimizer = optimiser\n",
    "\n",
    "PATH = \"best_all.pt\"\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimiser_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
